# Transformative AI safety working group at Stanford

## Purpose

By "transformative AI", we mean "roughly and conceptually, AI that precipitates a transition comparable to (or more significant than) the agricultural or industrial revolution" (quoting from the [Open Philanthropy Project blog](https://www.openphilanthropy.org/blog/some-background-our-views-regarding-advanced-artificial-intelligence#Sec1) -- see also the more detailed definition #2 in that post).

## Background reading

A recommended background reading list can be found [here](http://shlegeris.com/ai-safety-reading-list).  Also recommended are [80000 Hours podcast episodes](https://80000hours.org/podcast/episodes/) on topics related to transformative AI.

## Schedule

- Geoffrey Irving (OpenAI): "AI Safety at OpenAI", 4/24, 5:30pm, Varian physics building, 3rd floor, room 355
- Rohin Shah (CHAI, UC Berkely), 5/2, 4pm, location TBD
- Eric Drexler (Future of Humanity Institute), "Comprehensive AI Services", 5/9, 4pm, location TBD
- Scott Garrabrant (MIRI), details TBD
- Jacob Steinhardt (UC Berkeley), details TBD

## Contact

Feel free to email Nate Thomas (ncthomas@stanford) if you have any questions.
